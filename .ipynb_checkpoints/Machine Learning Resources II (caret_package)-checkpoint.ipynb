{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical Machine Learning\n",
    "\n",
    "## 2.- Stage II: \n",
    "## _\" The importance of caret package in the ML process. \"_\n",
    "\n",
    "Welcome to the stage II _dataAnalyst_player1_.\n",
    "If you are hereis because you already has the basis of the 'steps'(strategy) along the machine learning process. Now we will put over the table new tools. 'Caret' is a R library to cope with bigger data for more complex algorithms. Why using it? because we have much more data than we saw before, and because it is optimized to get results faster and in unexplored but, many times, better ways.\n",
    "So let's start with the process again: \n",
    "1. Question (ok)\n",
    "2. Collecting data\n",
    "3. Choosing features\n",
    "4. Running the algorithm 'A'\n",
    "5. Evaluation\n",
    "\n",
    "Are you happy with the results? \n",
    "\n",
    "If *not*, let's run all the process again with little arranges. So : \n",
    "2. Collecting more data! (and more and more...)\n",
    "3. Choosing other more features(or other differents)\n",
    "4. Running the same or other algorithm\n",
    "5. Re-evaluation.\n",
    "Are you happy with the results? \n",
    "If *not*, well.. maybe you are not an expert. And you need to be more in deeper about what are u doing wrong... Let's see everything you are doing more in deeper. Step-by-step. Take it easy man!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### _2.-Collected data_\n",
    "Golden rule: More data, (normally) better results.\n",
    "\n",
    "* Prepare your data\n",
    " * Data slicing\n",
    " * Training options\n",
    " * Plotting predictors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "library(caret);\n",
    "#install.packages(\"e1071\");\n",
    "library(e1071);\n",
    "library(kernlab);\n",
    "\n",
    "#1.-Loading data 'spam' from kernlab to use it as an example for caret package\n",
    "print(\"Loading data 'spam' from kernlab to use it as an example of: using caret package\" )\n",
    "data(spam)\n",
    "cat(\"Loaded succesfully! \\nBasic checking of:\\n\\t-1)class of data loaded\\n\\t-2)colnames\\n\\t-3)str\\n\\t-4)spam\")\n",
    "\n",
    "#1)\n",
    "class(spam)\n",
    "#2)\n",
    "colnames(spam)\n",
    "#3)\n",
    "str(spam)\n",
    "#4)\n",
    "dim(spam)\n",
    "\n",
    "#Creating a data partition from the spam$type column\n",
    "print(\"Creating a data partition from the spam$type column, which contains only these values\")\n",
    "unique(spam$type)\n",
    "print(\"using createDataPartition function we create a matrix with 75% of indexes of the total dataFrame. we store this data in a variable called: inTrain\")\n",
    "inTrain <- createDataPartition(y=spam$type,\n",
    "                                p=0.75,\n",
    "                                list=FALSE)\n",
    "\n",
    "print(\"Class of data 'inTrain':\")\n",
    "class(inTrain)\n",
    "print(\"Colnames of matrix 'inTrain':\")\n",
    "colnames(inTrain)\n",
    "print(\"take a look of the first rows of the matrix\")\n",
    "head(inTrain)\n",
    "\n",
    "print(\"extract those inTrain indexes from the dataset to create a trainingDataSet\")\n",
    "training <- spam[inTrain,]\n",
    "\n",
    "print(\"the rest of indexes not 'inTrain' will be the testDataSet\")\n",
    "testing <- spam[-inTrain,]\n",
    "\n",
    "print(\"checking the dimensions of the training dataset. n? of rows should be a 75% of the original data frame\")\n",
    "dim(training)\n",
    "\n",
    "\n",
    "print(\"#============================\")\n",
    "print(\"FITTING A MODEL.\") \n",
    "print(\" this model would be able to describe the behavior of this data\")\n",
    "#SMAP Example: Fit a model\n",
    "print(\"setting a seed to make this data reproducible. seed = 32343\")\n",
    "set.seed(32343)\n",
    "\n",
    "print(\"____________________________________\")\n",
    "print(\"train(type ~., data = training, method = 'glm'')\")\n",
    "print(\"____________________________________\")\n",
    "modelFit <- train(type ~., data = training, method = \"glm\") \n",
    "print()\n",
    "class(modelFit)\n",
    "\n",
    "print(\"I use ~. (tilde and dot) to say use all the other variables in this data frame in order to predict the type. \")\n",
    "print(\"And I tell which data ser I want to build the training model on and so, in this case, the training data set we created on the precious slide.\")\n",
    "print(\"And then I just tell which of the methods that I'd like to use, and so you can use GLM or you can use a bunch of other different models.\")\n",
    "\n",
    "#!!!#  And so what this does is it'll create a model fit from the train function, and as we use the 3451 samples in a training set and the 57 predictors to predict which class you're belonging to based on a model, a GLM model.  \n",
    "#      And so what it can do is it can do a bunch of different ways  of testing whether this model will work well  and using it to select the best model.  And in this case it used resampling.  And it does bootstrapping with 25 replicates, and it corrects  for the potential bias that might come from bootstrap sampling.\n",
    " \n",
    "\n",
    "cat(\"\\tSo once we fit that model, we can actually look at the model, and so the way we can do that is look at the finalModel component of the modelFit object. \\n\\tAnd the way you do that is you take the modelFit object, and then you type dollar sign and then always the same finalModel. It will tell you what are the actual fitted values that you got for that GLM model.\")\n",
    "modelFit$finalModel\n",
    "\n",
    "#\n",
    "cat(\"\\tThen you predict on new samples by using the predict command.\n",
    "Again, it's a unified framework, so we just type predict. We pass it the modelFit that we got from the train, function in carrot, and we pass it which data we would like it to predict on. \\n\\tSo in this case, the new data is the testing data.\")\n",
    " \n",
    "cat(\"_____________________________________\\n\\tpredictions <- predict(modelFit, newdata=testing)\\n_____________________________________\")\n",
    "predictions <- predict(modelFit, newdata=testing)\n",
    "predictions\n",
    "\n",
    "\n",
    "cat(\"\\t When you do that, it will give you a set of predictions that correspond to the responses, and you can use those to TRY TO EVALUATE WHETHER YOUR MODEL FIT WORKS VERY WELL OR NOT.\\n\\tOne way that you can do that is by calculating the confusion matrix, so that's using this confusion matrix function, and so note the capital M here. Don't miss that when you're typing confusion matrix. Then you pass in the predictions that you got from your model fit. And then the actual outcome on the testing samples. So in this case, it was the type or whether it was spam or ham message. And then it will record the confusion matrix.\\n\\t\")\n",
    "\n",
    "\n",
    "print(\"confusionMatrix(predictions, testing$type)\")\n",
    "confusionMatrix(predictions, testing$type)\n",
    "\n",
    "cat(\"So it'll tell you a table for which of the cases that you predicted to be nonspam or  actually nonspam, which is the cases where it was  spam, and you predicted to be spam and so forth\\n\\tAnd then it gives you a bunch of summary statistics.\\n\\tSo for example, the accuracy, a 95 percent confidence interval for the accuracy,  and then a bunch of information about how well they correspond in other categories.\")\n",
    "# So, for example, the sensitivity and the specificity of that.  So the confusion matrix function wraps a bunch of different accuracy measures  that you might want to get out when you're evalutating the model fit. For a lot more information about caret, we're going to cover a lot of it  in this class in terms of how do you actually apply the caret package.  \n",
    "#!!!#  But I found that these tutorials are actually very nice, and they can  be very useful for covering material that we don't cover in this class. And there's also a very nice paper in the journal of  statistical software that introduces the caret  package if you want further information.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=====================\n",
    "#Week 2:\n",
    "#Training Options\n",
    "#=====================\n",
    "cat(\"loading required libraries for this example:\\n\\t-caret\\n\\t-kernlab\")\n",
    "library(caret);\n",
    "library(kernlab);\n",
    "print(\"loading dataset 'spam'\")\n",
    "data(spam);\n",
    "\n",
    "print(\"procedure of createDataPartition\")\n",
    "inTrain <- createDataPartition(y= spam$type, \n",
    "                               p=0.75,\n",
    "                               list=FALSE)\n",
    "training <- spam[inTrain,]\n",
    "testing <- spam[-inTrain,]\n",
    "\n",
    "#dim(training)\n",
    "\n",
    "print(\"procedure of train\") #more info about '~' tilde in https://www.datacamp.com/community/tutorials/r-formula-tutorial\n",
    "modelFit <- train(type~., data=training, method= \"glm\")\n",
    "\n",
    "prnt(\"you can use a large set of options for training\")# So, here are a couple of them. One, you can use this preProcess parameter to set a bunch of preprocessing options. We'll talk about that in a future lecture.  You can also set weights.  In other words, you can upweight or downweight certain observations.  These are particularly useful if you have very unbalanced training set where you  have a lot more examples of one type than another.  You can set the metric, so by default for factor variable, in other words for  categorical variables the default metric is accuracy that it's trying to maximize. For continuous variables it's the root mean squared error,  like we talked about in a previous lecture.\n",
    "\n",
    "\n",
    "\n",
    "args(caret::train.default)\n",
    "\n",
    "cat('_______________________________________\\n\n",
    "  train(x, y, method = \"rf\", preProcess = NULL, ...,\n",
    "    weights = NULL, metric = ifelse(is.factor(y), \"Accuracy\", \"RMSE\"),\n",
    "    maximize = ifelse(metric %in% c(\"RMSE\", \"logLoss\", \"MAE\"), FALSE, TRUE),\n",
    "    trControl = trainControl(), tuneGrid = NULL,\n",
    "    tuneLength = ifelse(trControl$method == \"none\", 1, 3))\\n\n",
    "________________________________________________________________\n",
    "    ')\n",
    "cat(\"you can use a large set of options for training.\n",
    " So, here are a couple of them.\n",
    "      \\tOne, you can use this preProcess parameter to set a bunch of preprocessing options.We'll talk about that in a future lecture.\n",
    "      \\tYou can also set weights. In other words, you can upweight or downweight certain observations. These are particularly useful if you have very unbalanced training set where you have a lot more examples of one type than another.\n",
    "      \\tYou can set the metric, so by default for factor variable, in other words for\n",
    "      categorical variables the default metric is accuracy that it's trying to maximize.\n",
    "      \\tFor continuous variables it's the root mean squared error, like we talked about in a previous lecture.\")\n",
    "\n",
    "print(\"You can also set a large number of other control parameters using this trControl parameter here and you have to pass it a call to this particular function, trainControl, which we'll talk about in a couple of slides.\")\n",
    "\n",
    "args(trainControl)\n",
    "\n",
    "#!!!#\n",
    "#So the Metric options are built-in to the train function for continuous outcomes. Our RMSE, or root mean squared error. You can also use RSquared. This is the RSquared that you get from a regression model if you remember that from the inference class. RSquared is a measure of linear agreement between the variables that you're predicting and the variables that you predict with.\n",
    "\n",
    "\n",
    "# For resampling, there are a bunch of methods that are offered,so this is again passed to the trainControl function.\n",
    "# You can use standard bootstrapping, you can use bootstrapping that adjusts for the fact that multiple samples are repeatedly resampled when you're doing that subsampling. This will reduce some of the bias due to bootstrapping. \n",
    "# You can use cross validation which is a method that we've talked about in previous lectures. \n",
    "# You could also use repeated cross validation if you want to do sub cross validation with different random draws. \n",
    "# You could use leave one out cross validation and remember there's a bias during its trade off between using large number of folds and smaller number of folds when doing cross validation. \n",
    "# You can also tell it the number of bootstrap samples or the number of subsamples to take and the number of times to repeat that subsampling if you're doing something like repeated cross validation. \n",
    "#   All of these parameters can be set. In general the defaults work pretty well, but if you have large numbers of samples or you have a model that requires fine tuning across a large number of parameters, you may want to increase for example the number of cross-validation or bootstrap samples that you take.\n",
    "\n",
    "\n",
    "#Setting the seed\n",
    "\n",
    "set.seed(1235)\n",
    "modelFit2 <- train(type~., data = training, method=  \"glm\")\n",
    "modelFit2\n",
    "\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===================\n",
    "#Ploting predictors\n",
    "#===================\n",
    "#Tested on R version 3.3.2\n",
    "#Ubuntu 16.04 LTS\n",
    "\n",
    "\n",
    "###===========================================\n",
    "#1#-Installing and calling required libraries\n",
    "###===========================================\n",
    "\n",
    "#install.packages(\"ISLR\")\n",
    "library(ISLR)\n",
    "#install.packages(\"ggplot2\")\n",
    "library(ggplot2)\n",
    "#install.packages(\"caret\")\n",
    "library(caret)\n",
    "#install.packages(\"Hmisc\")\n",
    "library(Hmisc)\n",
    "#Thirs library once loaded and runned restart the computer. It enable to create some plots.\n",
    "library(gridExtra)\n",
    "#install.packages(\"Cairo\")\n",
    "#setHook(packageEvent(\"grDevices\", \"onLoad\"),\n",
    "#        function(...) grDevices::X11.options(type='cairo'))\n",
    "#options(device='x11')\n",
    "\n",
    "\n",
    "###====================================================\n",
    "#2#-Loading dataset Wage and looking at the 'landscape'\n",
    "###====================================================\n",
    "\n",
    "data(Wage)\n",
    "summary(Wage)\n",
    "\n",
    "\n",
    "###=========================\n",
    "#3#-Get trainings/test_sets \n",
    "###=========================\n",
    "#...by mean of function 'createDataPartition'\n",
    "\n",
    "inTrain <- createDataPartition(y=Wage$wage,\n",
    "                            p=0.7,\n",
    "                            list= FALSE)\n",
    "training <- Wage[inTrain,];\n",
    "testing <- Wage[-inTrain,];\n",
    "#dim(training); --[1] 2102   11\n",
    "#dim(testing); --[1] 898  11\n",
    "\n",
    "\n",
    "\n",
    "###==========\n",
    "#4#-Plotting\n",
    "###==========\n",
    "#[1] Across different features\n",
    "#...by mean of function 'featurePlot' (Wrapper for Lattice Plotting of Predictor Variables)\n",
    "\n",
    "#Feature plot (caret package)\n",
    "featurePlot(x = training[, c(\"age\", \"education\", \"jobclass\")], \n",
    "            y = training$wage,\n",
    "            plot = \"pairs\")\n",
    "\n",
    "#[2] Across 2 features (2-D plot)\n",
    "#NOTE: If you have problems in Ubuntu for plotting because the font Helvetica, just try the procedure described here:\n",
    "#sudo apt-get install t1-xfree86-nonfree ttf-xfree86-nonfree ttf-xfree86-nonfree-syriac xfonts-75dpi xfonts-100dpi\n",
    "#From: https://askubuntu.com/questions/449578/x11-font-adobe-helvetica-s-s-d-face-2-at-size-11-could-no\n",
    "#Later restart the computer\n",
    "\n",
    "#Qplot (ggplot2 package)\n",
    "qplot(age, wage, data = training)\n",
    "\n",
    "#[3] Across 2 features (2-D plot) with different colors based in other 3rd feature\n",
    "#Qplot with color (ggplot2 package)\n",
    "qplot(age, wage, colour = jobclass, data = training)\n",
    "\n",
    "\n",
    "#Explanation?\n",
    "#[4]  Across 2 features (2-D plot) with different colors based in other 3rd feature. With lines \n",
    "#Add regression smoothers (ggplot2 package)\n",
    "qq <- qplot(age, wage, colour = education, data = training)\n",
    "qq+ geom_smooth(method= \"lm\", formula = y~x) #linear regression formula\n",
    "\n",
    "\n",
    "#[5]Making factors for BoxPlots\n",
    "#cut2, making factors (Hmisc package)\n",
    "cutWage <- cut2(training$wage, g = 3)\n",
    "table(cutWage)\n",
    "\n",
    "#Boxplots with cut2\n",
    "\n",
    "p1 <- qplot(cutWage, age, data=training, fill=cutWage, geom= c(\"boxplot\"))\n",
    "\n",
    "p1\n",
    "\n",
    "#Boxplots with points overlayed\n",
    "p2 <- qplot(cutWage, age, data = training, fill=cutWage, geom=c(\"boxplot\", \"jitter\"))\n",
    "grid.arrange(p1,p2,ncol=2)\n",
    "\n",
    "#Tables\n",
    "t1 <- table(cutWage, training$jobclass)\n",
    "t1\n",
    "\n",
    "\n",
    "prop.table(t1,1)\n",
    "\n",
    "#[5] Histogram density\n",
    "#Density plots\n",
    "qplot(wage, colour= education, data = training, geom= \"density\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### _3.-Pre-process your data_\n",
    "Think about how to organize the variables to optimize the process of classification\n",
    "\n",
    "\n",
    "* Basic preprocessing\n",
    "* Covariate creation\n",
    "* Preprocesing with Principal Component analysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#week2_IV_basicPreprocessing\n",
    "\n",
    "\n",
    "library(caret);\n",
    "library(kernlab);\n",
    "#install.packages(\"e1071\")\n",
    "library(e1071)\n",
    "#install.packages(\"RANN\")\n",
    "library(RANN)\n",
    "\n",
    "data(spam)\n",
    "\n",
    "#So, why preprocess? Here again I'm loading the later, the caret package, and I'm learning the kernlab package and then I'm attaching the spam data. Again just like I talked about previously, when you're deciding how to preprocess data, or how to explore data we only look at the training set. So, we split data right away into training and testing data and we set the testing data aside for later. Now if I look at one of the variables, so again, this is spam data, so we're trying to predict whether the data is spam or if it's good emails, ham. And, so the variables are things like how many capitals do we see in a row?   What's the run length for the number of capitals in a row in an email? If you take, make a histogram of those values, you see, for example,. That almost all of the run links are very small, but there are a few that are much, much larger. This is an example of a variable that is very skewed, and, so it's very hard to deal with in model based predictors and so you might want to preProcess. So, if you take the mean of this variable, it's about 4.7. But the standard deviation is huge, it's much much larger. So, it's much more highly variable variable. And so, what you might want to do is do some sort of preprocessing, so the machine learning algorithms don't get tricked by the fact that it's skewed and highly variable.\n",
    "\n",
    "inTrain <- createDataPartition(y=spam$type,\n",
    "                                p=0.75,\n",
    "                                list=FALSE)\n",
    "training <- spam[inTrain,]\n",
    "testing <- spam[-inTrain,]\n",
    "\n",
    "hist(training$capitalAve,main=\"\", xlab=\"ave, capital run length\")\n",
    "\n",
    "#-----\n",
    "mean(training$capitalAve)\n",
    "\n",
    "sd(training$capitalAve)\n",
    "\n",
    "#------\n",
    "trainCapAve  <- training$capitalAve\n",
    "trainCapAveS <- (trainCapAve - mean(trainCapAve))/sd(trainCapAve)\n",
    "mean(trainCapAveS)\n",
    "\n",
    "#----------\n",
    "\n",
    "sd(trainCapAveS)\n",
    "\n",
    "#-----------\n",
    "\n",
    "testCapAve <- testing$capitalAve\n",
    "testCapAveS <- (testCapAve -mean(trainCapAve))/sd(trainCapAve)\n",
    "mean(testCapAveS)\n",
    "\n",
    "#------------------\n",
    "\n",
    "sd(testCapAveS)\n",
    "\n",
    "#-----\n",
    "\n",
    "preObj <- preProcess(training[,-58], method=c(\"center\",\"scale\"))\n",
    "trainCapAves <- predict(preObj, training[,-58])$capitalAve\n",
    "\n",
    "mean(trainCapAveS)\n",
    "\n",
    "sd(trainCapAveS)\n",
    "\n",
    "#-----------\n",
    "testCapAveS <-predict(preObj, testing[,-58])$capitalAve\n",
    "\n",
    "mean(testCapAveS)\n",
    "\n",
    "#------\n",
    "\n",
    "sd(testCapAveS)\n",
    "\n",
    "#-----------\n",
    "\n",
    "set.seed(32343)\n",
    "modelFit <- train(type ~.,data=training, preProcess=c(\"center\",\"scale\"), method=\"glm\")\n",
    "\n",
    "modelFit\n",
    "\n",
    "preObj <- preProcess(training[,-58], method=c(\"BoxCox\"))\n",
    "trainCapAveS <- predict(preObj, training[,-58])$capitalAve\n",
    "par(mfrow=c(1,2));\n",
    "hist(trainCapAveS);\n",
    "qqnorm(trainCapAveS)\n",
    "\n",
    "#========================\n",
    "\n",
    "set.seed(13343)\n",
    "\n",
    "#Make some values NA\n",
    "training$capAve <- training$capitalAve\n",
    "selectNA <- rbinom(dim(training)[1], size=1, prob=0.05)==1\n",
    "training$capAve[selectNA] <- NA\n",
    "\n",
    "#Impute and standardize\n",
    "preObj <- preProcess(training[,-58],method=\"knnImpute\")\n",
    "capAve <- predict(preObj, training[, -58])$capAve\n",
    "\n",
    "# Standarize true values\n",
    "capAveTruth <- training$capitalAve\n",
    "capAveTruth <- (capAveTruth-mean(capAveTruth))/sd(capAveTruth)\n",
    "\n",
    "\n",
    "#---Standarizing imputing data\n",
    "quantile(capAve-capAveTruth)\n",
    "\n",
    "quantile((capAve-capAveTruth)[selectNA])\n",
    "\n",
    "quantile((capAve-capAveTruth)[!selectNA])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###week2_V_Covariate creation\n",
    "\n",
    "library(kernlab); data(spam)\n",
    "spam$capitalAveSq <- spam$capitalAve^2 \n",
    "\n",
    "#Load example data\n",
    "#install.packages(\"ISLR\")\n",
    "library(ISLR);\n",
    "library(caret);\n",
    "data(Wage);\n",
    "inTrain <- createDataPartition(y=Wage$wage,\n",
    "                                 p=0.7,\n",
    "                                 list=FALSE)\n",
    "training <- Wage[inTrain,];\n",
    "testing <- Wage[-inTrain,]\n",
    "\n",
    "#Common covarites to add, dummy variables\n",
    "#-basic idea- convert factor variables to INDICATOR variables\n",
    "\n",
    "table(training$jobclass)\n",
    "\n",
    "dummies <- dummyVars(wage~jobclass, data = training)\n",
    "head(predict(dummies, newdata=training))\n",
    "\n",
    "#Removing Zero Covariates\n",
    "\n",
    "nsv <- nearZeroVar(training, saveMetrics = TRUE)\n",
    "nsv\n",
    "\n",
    "\n",
    "#Spline basis\n",
    "library(splines)\n",
    "bsBasis <- bs(training$age, df=3)\n",
    "bsBasis\n",
    "\n",
    "#Fitting curves with splines\n",
    "lm1 <- lm(wage~bsBasis, data=training)\n",
    "plot(training$age, training$wage, pch=19, cex= 0.5)\n",
    "points(training$age, predict(lm1, newdata=training), col = \"red\", pch=19, cex = 0.5)\n",
    "\n",
    "#SPlines on the test set\n",
    "\n",
    "predict(bsBasis, age = testing$age)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================\n",
    "#PRE-PROCESSING WITH PRINCIPAL COMPONENT ANALYSIS\n",
    "#=================================================\n",
    "\n",
    "#Loading libraries\n",
    "\n",
    "library(caret);\n",
    "library(kernlab);\n",
    "\n",
    "#Loading data 'SPAM'\n",
    "data(spam)\n",
    "\n",
    "#[2]Splitting the data into training and test datasets\n",
    "inTrain <- createDataPartition(y=spam$type,\n",
    "                               p=0.75,\n",
    "                               list=FALSE)\n",
    "\n",
    "training <- spam[inTrain,]\n",
    "testing <-spam[-inTrain,]\n",
    "\n",
    "#[3] Correlation \n",
    "M<-abs(cor(training[,-58])) #i leave out the 58 column in this dataset (which is the outcome column) and i calculate the correlation of all the predictor ariables and i take the absolute value.\n",
    "#so I am looking for all thse predictor variables which a has a very high correlation or are very siilar one to each other. Every variable has a correlation 1 with itself. I am not interested in those variable correlation 1 with isself.\n",
    "diag(M) <- 0 #so i set in this diagonal matrix all those variables correlate with itself as 0.\n",
    "\n",
    "which(M >0.8, arr.ind=T) #and then look which of these correlations have high correlation with each other. which of these variables have an high correlation greater than 0.8?\n",
    "\n",
    "#As a result here appears 2 variables with very high correlation.\n",
    "\n",
    "\n",
    "#If i look in the spam dataset at the columns 34 and 32, and if i plot these variables one to each other.\n",
    "#correlated predictors\n",
    "names(spam)[c(34,32)]\n",
    "\n",
    "plot(spam[,34],spam[,32])\n",
    "\n",
    "#Basic PCA Idea,\n",
    "# we might not need every predictor\n",
    "# a weighted combination of predictors might be better\n",
    "# we should pick this combination to capture the \"most information\" possible\n",
    "# benefits\n",
    "   # reduced number of predictors\n",
    "   # reduced noise (due to averaging)\n",
    "\n",
    "\n",
    "#We could rotate the plot\n",
    "\n",
    "X <- 0.71*training$num415 + 0.71*training$num857\n",
    "Y <- 0.71*training$num415 - 0.71*training$num857\n",
    "\n",
    "plot(X,Y)\n",
    "\n",
    "\n",
    "#Related problems....\n",
    "#You have multivariate variables X1,..., Xn so X1 = (X11, ..., X1m)\n",
    "\n",
    " #Find a new set of multivariate variables that are uncorrelated and explian as much variance as possible\n",
    " #If you put all the variables together in one matrix, find the best matrix created with fewer variables (lower rank) that explians the original data.\n",
    "\n",
    "#the first goal is statistical and the second goal is data compression.\n",
    "\n",
    "#Related solutions - PCA/SVD\n",
    "#svd-\n",
    "#If X is a matrix with each variable in a column and each observation in a row then the SVD is a \n",
    "\n",
    "\n",
    "#Principal components in R -prcomp\n",
    "smallSpam <- spam[,c(34,32)]\n",
    "prComp <- prcomp(smallSpam)\n",
    "\n",
    "plot(prComp$x[,1], prComp$x[,2])\n",
    "#here in this plot the first principal component looks like a lot as adding these two variables together and the second principal component looks like a lot as asubstracting these two variables. as we saw in the plot before.\n",
    "#so why we do principal component? \n",
    "#principal component allows you to add and susbstract even more than 2 variables.\n",
    "\n",
    "#cnfusion matri to see the variability:\n",
    "prComp$rotation\n",
    "\n",
    "\n",
    "#PCA on SPAM data\n",
    "typeColor <- ((spam$type==\"spam\")*1 + 1) #selecting the color for spam data ad non spam data\n",
    "prComp <- prcomp(log10(spam[,-58]+1)) #here we are going to calculate theprincipal component in the entire dataset. I applied the log10 transformation function in this dataset, adn I added+1. I did this to make the data to look a little more Guassian.\n",
    "plot(prComp$x[,1], prComp$x[,2], col=typeColor, xlab=\"PC1\", ylab=\"PC2\")#plotting\n",
    "\n",
    "#using the caret function pre_process\n",
    "preProc <- preProcess(log10(spam[,-58]+1), method=\"pca\", pcaComp=2)#pcaComp to say the number of principal compoonents to compute\n",
    "spamPC <- predict(preProc, log10(spam[,-58]+1))#we pass that preprocess object and the dataset to the predict function, and it give us the principal coponent. \n",
    "plot(spamPC[,1], spamPC[,2], col=typeColor)\n",
    "#there is a little of separation between spam and no spam messages\n",
    "#Preprocessing with PCA\n",
    "preProc <- preProcess(log10(training[,-58]+1), method = \"pca\", pcaComp = 2)\n",
    "trainPC <- predict(preProc, log10(training[,-58]+1)) #you can reate a training set by usign the predicr funnction\n",
    "###!! ERROR in the next step. why?\n",
    "#modelFit <-train(training$type ~ ., method =\"glm\", data=trainPC) \n",
    "modelFit <- train(y=training$type,method=\"glm\",x=trainPC)\n",
    "#modelFit <-train(type ~ ., method =\"glm\", data=training)# and then fitting a model that relates the training variable to the PCA\n",
    "\n",
    "#Preprocessing with PCA\n",
    "#in the test  data set you have to use the same principal component you calculated in the trained set\n",
    "testPC <- predict(preProc, log10(testing[,-58]+1))\n",
    "#confussion matrix to get the accuracy\n",
    "###!! ERROR in the next step. why?\n",
    "\n",
    "confusionMatrix(testing$type, predict(modelFit, testPC))\n",
    "#\n",
    "#Alternative(sets  # of PCs)\n",
    "#\n",
    "#you can decide for this analisis not to use the prediction separately. \n",
    "###!! ERROR in the next step. why?\n",
    "#modelFit <- train(training$type ~., method=\"glm\", preProcess=\"pca\", data=training)\n",
    "modelFit <- train(y= training$type , method=\"glm\", preProcess=\"pca\", x=training)\n",
    "#\n",
    "confusionMatrix(testing$type, predict(modelFit, testing))\n",
    "\n",
    "#Final thoughts on PCs\n",
    "#...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _4.-Running an algorithm_\n",
    "This is a neccesary step, but don't take too much time on it. \n",
    "\n",
    "* Predicting with regression\n",
    "* Predicting with Regression Multiple Covariates\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#week2_VII_Predicting with regression\n",
    "\n",
    "#Example Old faitful eruptions\n",
    "\n",
    "library(caret);\n",
    "data(faithful);\n",
    "set.seed(333)\n",
    "inTrain <- createDataPartition(y=faithful$waiting,\n",
    "                               p=0.5,\n",
    "                               list=FALSE)\n",
    "\n",
    "trainFaith <- faithful[inTrain,];\n",
    "testFaith <- faithful[-inTrain,]\n",
    "head(trainFaith)\n",
    "\n",
    "\n",
    "#Eruption duration versus waiting time\n",
    "plot(trainFaith$waiting, trainFaith$eruptions, pch=19, col = \"blue\", xlab= \"Waiting\", ylab = \"Duration\")\n",
    "\n",
    "#Fit a linear model\n",
    "\n",
    "#Edi = b0 + b1 WTi + ei\n",
    "lm1 <- lm(eruptions~waiting, data = trainFaith)\n",
    "summary(lm1)\n",
    "\n",
    "#Model fit\n",
    "plot(trainFaith$waiting, trainFaith$eruptions, pch= 19, col= \"blue\", xlab= \"Waiting\", ylab=\"Duration\")\n",
    "\n",
    "lines(trainFaith$waiting, lm1$fitted, lwd=3)\n",
    "\n",
    "\n",
    "#Predict a new value\n",
    "#ÊD = ^b0+ ^b1 WT\n",
    "\n",
    "coef(lm1)[1] + coef(lm1)[2]*80\n",
    "\n",
    "newdata <- data.frame(waiting=80)\n",
    "predict(lm1, newdata)\n",
    "\n",
    "#Plot predictions - training and test\n",
    "par(mfrow = c(1,2))\n",
    "plot(trainFaith$waiting, trainFaith$eruptions, pch=19, col = \"blue\", xlab=\"Waiting\", ylab=\"Duration\")\n",
    "lines(trainFaith$waiting, predict(lm1), lwd=3)\n",
    "plot(testFaith$waiting, testFaith$eruptions, pch=19, col = \"blue\", xlab=\"Waiting\", ylab=\"Duration\")\n",
    "lines(testFaith$waiting, predict(lm1, newdata=testFaith), lwd=3)\n",
    "\n",
    "#Get training set/test set errors\n",
    "#CAlculate RMSE on training\n",
    "sqrt(sum((lm1$fitted-trainFaith$eruptions)^2))\n",
    "\n",
    "#Calculate RMSE on test\n",
    "sqrt(sum((predict(lm1, newdata=testFaith)-testFaith$eruptions)^2))\n",
    "\n",
    "\n",
    "#Prediction intervals\n",
    "\n",
    "pred1 <- predict(lm1, newdata=testFaith, interval=\"prediction\")\n",
    "ord <- ord(testFaith$waiting)\n",
    "plot(testFaith$waiting, testFaith$eruptions, pch=19, col =\"blue\")\n",
    "matlines(testFaith$waiting[ord], pred1[ord,], type=\"l\",,col=c(1,2,2),lty=c(1,1,1),lwd=3)\n",
    "\n",
    "#Same process with caret\n",
    "modFit <- train(eruptions~waiting, data=trainFaith,method = \"lm\")\n",
    "summary(modFit$finalModel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=========================================\n",
    "#PREDICTION WITH REGRESSION\n",
    "#=========================================\n",
    "\n",
    "#####\n",
    "#####----Example : Wage data------\n",
    "#####\n",
    "\n",
    "library(ISLR);\n",
    "library(ggplot2);\n",
    "library(caret);\n",
    "data(Wage);\n",
    "Wage <- subset(Wage, select=-c(logwage))\n",
    "summary(Wage)\n",
    "\n",
    "#Getting training/testSets\n",
    "inTrain <- createDataPartition(y=Wage$wage,\n",
    "                               p=0.7,\n",
    "                               list=FALSE)\n",
    "training <- Wage[inTrain,]; \n",
    "testing <- Wage[-inTrain,]\n",
    "dim(training);\n",
    "dim(testing)\n",
    "\n",
    "#Feature plot\n",
    "\n",
    "featurePlot(x=training[,c(\"age\", \"education\", \"jobclass\")], y = training$wage, plot = \"pairs\")\n",
    "\n",
    "#Plot age vs wage\n",
    "qplot(age, wage, data = training)\n",
    "\n",
    "#Plot age vs wage colour by jobclass\n",
    "qplot(age, wage, colour=jobclass, data=training)\n",
    "\n",
    "#Plot age vs wage colour by education\n",
    "qplot(age, wage, colour=education, data=training)\n",
    "\n",
    "\n",
    "#Fit a linear model\n",
    "#EDi = b0 + b1age +b2I(jobclassi=\"information\") + summaroty [...]\n",
    "\n",
    "modFit<- train(wage~age+jobclass+education, method = \"lm\", data = training)\n",
    "finMod <- modFit$finalModel\n",
    "print(modFit)\n",
    "\n",
    "#Diagnstics\n",
    "plot(finMod, 1, pch=19, cex=0.5, col=\"#00000010\")\n",
    "\n",
    "#Color by variables not used in the model\n",
    "qplot(finMod$fitted,finMod$residuals, colour=race,  data=training)\n",
    "\n",
    "#Plot by index\n",
    "plot(finMod$residuals, pch=19)\n",
    "\n",
    "#Predicted vesrus trith in test set\n",
    "pred <- predict(modFit, testing)\n",
    "qplot(wage, pred, colour=year, data=testing)\n",
    "\n",
    "#If you want to use all covariates\n",
    "modFitAll <- train(wage~., data=training, method=\"lm\")\n",
    "pred <- predict(modFitAll, testing)\n",
    "qplot(wage, pred, data=testing)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
